h1. Automated Assignment of Human Readable Descriptions (AHRD)

Protein function has often been transferred from characterized proteins to
novel proteins based on sequence similarity, e.g. using the best BLAST hit. To
assign human readable descriptions to predicted proteins we developed a new
program called Automatic assignment of human readable descriptions (AHRD). We
aim to select descriptions that are concise and informative, precise in regard
to function and use standard nomenclature. AHRD scores BLAST hits taken from
searches against different databases on the basis of the trust put into these
databases and the local alignment quality. The BLAST hit descriptions are
tokenized into informative words and a lexical analysis scores these tokens
according to their frequency and the quality of the BLAST hits they occur in.
Shared tokens with Gene-Ontology Annotations increase the description-scoring
in order to use standard nomenclature where possible. Finally the best scoring
description is assigned.

h2. 1 Getting started

h3. 1.1 Requirements

AHRD is a Java-Program which requires Java 1.5 or higher and ant.


h3. 1.2 Installation

h4. 1.2.1 Get AHRD

Copy (clone) AHRD to your computer using git via command-line:
<pre>git clone git://github.com/groupschoof/AHRD.git
git checkout tags/2.0.2-stable</pre>

h4. 1.2.2 Build the executable jar

Running <pre>ant dist</pre> will create the executable JAR-File: ./dist/ahrd.jar

An executable jar (Java 1.6 compiled) of the paper release version can also be downloaded here:
https://www3.uni-bonn.de/cropbio/tools-and-databases

h2. 2 Usage

All AHRD-Inputs are passed to AHRD in a single YML-File.
See ./ahrd_example_input.yml for details.
(About YAML-Format see <a href="http://en.wikipedia.org/wiki/YAML">Wikipedia</a>)

Basically AHRD needs a FASTA-File of amino acid sequences and different files
containing the results from the respective BLAST searches, in our example we
searched three databases: Uniprot/trEMBL, Uniprot/Swissprot and TAIR10. Note,
that AHRD is generic and can make use of any number of different Blast
databases that do not necessarily have to be the above ones. If e.g. annotating
genes from a fungal genome searching yeast databases might be more
recommendable than using TAIR (_Arabidopsis thaliana_).

All parameters can be set manually, or the default ones can be used as given in
the example input file ./test/resources/ahrd_input_test_run.yml (see section
Parameters).

In order to parallelize the protein function annotation processes,  
AHRD can be run on batches of recommended size between 1,000 to 2,000 proteins. 
If you want to annotate large protein sets use the included Batcher to split your
input-data into Batches of appropriate size (see section Batcher). 
As of Java 7 or higher AHRD is quite fast and batching might no longer be necessary.

h3. 2.1 AHRD Example run

<pre>java -Xmx2g -jar ./dist/ahrd.jar ahrd_example_input.yml </pre>

or just execute

<pre>ant test.run </pre>

h3. 2.2 Input

Example files for all input files can be found under ./test/resources/

h4. 2.2.1 Required input data

# Protein sequences in fasta format
# BLAST seach results in pairwise format for protein sequences

(If you run AHRD in batches the blast search results need to be batched in the same way as the fasta files.)

Recommended BLAST-Search:

For your query proteins you should start independent BLAST searches e.g.
in the three different databases mentioned above:

<pre>
blastall -p blastp -i proteins.fasta -o swissprot_blastout.pairwise -d swissprot.fasta -e 0.0001 -v 200 -b 200 -m 0
</pre>

_Note_ We are currently working on extending AHRD to parse Blast+ output. As of now, legacy blast is still a requirement.

h4. 2.2.2 Optional input data

AHRD optionally considers other protein function annotations. Formerly this was requested in genome projects [1]. We do _not_ recommend their use any more, due to AHRD's excellent performance without this protein function information.

# Domain search results from InterProScan in raw format
# Gene ontology annotations in csv format

In case InterProScan results are given as input, AHRD needs the Interpro database XML- and dtd-file.

h4. 2.2.3 Required config files

# Input yml with all pathes and parameters according to your needs (see ahrd_example_input.yml and section Parameters)
# Blacklists and filters (they can either be used as provided or can be adapted to your needs and databases). Each of these files contains a list of valid Java regular expressions, one per line. For details on Java regular expressions please refer to http://docs.oracle.com/javase/tutorial/essential/regex/.
## *Description blacklist* (Argument @blacklist: ./test/resources/blacklist_descline.txt@) - Any Blast-Hit's description matching one of the regular expressions in this file will be ignored.
## *Description filter* for each single blast database (Argument @filter: ./test/resources/filter_descline_sprot.txt@) - Any part of a Blast-Hit description that matches any one of the regular expressions in this file will be deleted from the description.
## *Token blacklist* (Argument @token_blacklist: ./test/resources/blacklist_token.txt@) - Blast-Hit's descriptions are composed of words. Any such word matching any one of the regular expressions in this file will be ignored by AHRD's scoring, albeit it will not be deleted from the description and thus might still be seen in the final output.

h5. 2.2.3.1 Test custom blacklists and filters

As explained in 2.2.3 AHRD makes use of blacklists and filters provided as Java regular expressions. You can test your own custom blacklists and filters:

# Put the strings representing Blast-Hit descriptions or words contained in them in the file @./test/resources/regex_list.txt@. Note, that each line is interpreted as a single entry.
# Put the Java regular expressions you want to test in file @./test/resources/match_list.txt@, using one regular expression per line.
# Execute @ant test.regexs@ and study the output.

Example Output for test string "activity", and regular expressions "(?i)interacting", and "(?i)activity" applied in serial:

<pre>[junit] activity 
[junit] (?i)interacting -> activity
[junit] (?i)activity -> </pre>

The above example demonstrates how the first regular expression does not match anything in the test string "activity", but after matching it against the second regular expression nothing remains, because the matched substring has been filtered out. As you can see, this test applies all provided regular expression _in order of appearance_ and shows what _remains_ of the provided test string after filtering with the provided regular expressions.


h3. 2.3 Batcher

AHRD provides a function to generate several input.yml files from large datasets, consisting of _batches_ of query proteins. For each of these batches the user is expected to provide the batch's query proteins in FASTA format, and one Blast result file for each database searched. The AHRD batcher will then generate a unique input.yml file and entry in a batch shell script to execute AHRD on the respective batches in parallel for example on a compute cluster using a batch-system like LSF. We recommend this for genome scale datasets.

To generate the mentioned input.yml files and batcher shell script that can subsequently be used to start AHRD in parallel use the batcher function as follows:
<pre>java -cp ./dist/ahrd.jar ahrd.controller.Batcher ./batcher_input_example.yml</pre>
You will have to edit @./batcher_input_example.yml@ and provide the following arguments. Note, that in the mentioned directories each file will be interpreted as belonging to one unique Batch, if and only if they have identical file names. 

# @shell_script:@ Path to the shell-script file which later contains all the statements to invoke AHRD on each supplied batch in parallel.
# @ahrd_call: "java -Xmx2048m -jar ./dist/ahrd.jar #batch#"@ This line will be the basis of executing AHRD on each supplied batch. The line _must_ contain @#batch#@ wich will be replaced with the input.yml files. To use a batch system like LSF this line has to be modified to something like @bsub -q normal 'java -Xmx2048m -jar ./dist/ahrd.jar #batch#'@
# @proteins_dir:@ The path to the directory the query protein batches are stored in.
# @batch_ymls_dir:@ The path to the directory the AHRD-Batcher should store the generated input.yml files in.
# @dir:@ Each database entry requires this argument, the path to the directory each batch's blast result file from searches in the corresponding Blast-database is located.
# @interpro_results_dir:@ The directory in which each Batch's @interproscan@ result file is located.
# @gene_ontology_results_dir:@ The directory in which each Batch's Gene Ontology annotation file is stored.
# @output_dir:@ The directory each AHRD run should create a subdirectory with the output for the processed batch.

_Batch-Name requirement:_ All above explained files belonging to the same Batch _must_ have the same name. This name must start with alpha-numeric characters and may finish with digits indicating the Batch's number. File extensions are allowed to be varying. 

h3. 2.4 Output

AHRD supports two different formats. The default one is a tab-delimited table.
The other is FASTA-Format.

h4. 2.4.1 Tab-Delimited Table

AHRD writes out a CSV table with the following columns:
# Protein-Accesion -- The Query Protein's Accession
# Blast-Hit-Accession -- The Accession of the Protein the assigned description was taken from.
# AHRD-Quality-Code -- explained below
# Human-Readable-Description -- The assigned HRD
# Interpro-ID (Description) -- If AHRD was started with InterProScan-Results, they are appended here.
# Gene-Ontology-ID (Name) -- If AHRD was started with Gene-Ontology-Annotations, they are appended here.

AHRD's quality-code consists of a four character string, where each character
is either <strong>'*'</strong> if the respective criteria is met or *'-'*
otherwise. Their meaning is explained in the following table:

| Position | Criteria |
| 1 | Bit score of the blast result is >50 and e-value is <e-10 |
| 2 | Overlap of the blast result is >60% |
| 3 | Top token score of assigned HRD is >0.5 |
| 4 | Gene ontology terms found in description line |

h4. 2.4.2 Fasta-Format

To set AHRD to write its output in FASTA-Format set the following switch in the input.yml:

<pre>
output_fasta: true
</pre>

AHRD will write a valid FASTA-File of your query-proteins where the Header will
be composed of the same parts as above, but here separated by whitespaces.

h3. 2.5 AHRD run using BLASTX results

In order to run AHRD on BLASTX results instead of BLASTP results you have to
modify the following parameters in the ahrd_example_input.yml:

<pre>token_score_bit_score_weight: 0.5
token_score_database_score_weight: 0.3
token_score_overlap_score_weight: 0.2</pre>

Since the algorithm is based on protein sequences and the BLASTX searches are
based on nucleotide sequence there will be a problem calculating the overlap
score of the blast result.  To overcome this problem the
token_score_overlap_score_weight has to be set to 0.0. Therefore the other two
scores have to be raised. These three parameters have to sum up to 1. The
resulting parameter configuration could look like this:

<pre>token_score_bit_score_weight: 0.6
token_score_database_score_weight: 0.4
token_score_overlap_score_weight: 0.0</pre>

h2. 3 Algorithm

Based on e-values the 200 best scoring blast results are chosen from each
database-search (e.g. Swissprot, TAIR, trEMBL). For all 600 resulting candidate
description lines a score is calculated using a lexical approach. First each
description line is passed through two regular expression filters. The first
filter discards any matching description line in order to ignore descriptions
like e.g. 'Whole genome shotgun sequence', while the second filter tailors the
description lines deleting matching parts, in order to discard e.g. the
trailing Species-Descriptions 'OS=Arabidopsis thaliana [...]". In the second
step the scoring each description line is split into single tokens, which are
passed through a blacklist filter, ignoring all matching tokens in terms of
score. Tokens are sequences of characters with a collective meaning. For each
token a score is calculated from three single scores with different weights,
the bit score, the database score and the overlap score. The bit score is
provided within the blast result. The database score is a fixed score for each
blast database, based on the description quality of the database. The overlap
score reflects the overlap of the query and subject sequence. In the second
step the sum of all token scores from a description line is divided by a
correction factor that avoids the scoring system from being biased towards
longer or shorter description lines. In the third step the predicted gene
ontology terms, if available, are used to evaluate the description lines and to
get a better ranking. Therefore only gene ontology terms with a probability
greater than 0.4 are used. From this ranking now the best scoring description
line can be chosen. In the last step a domain name provided by InterProScan
results, if available, is extracted and appended to the best scoring
description line for each uncharacterized protein.

In the end for each uncharacterized protein a description line is selected that
comes from a high-scoring BLAST match, that contains words occurring frequently
in the descriptions of highest scoring BLAST matches and that does not contain
meaningless "fill words". If available an assigned Interpro domain is appended
to the description line and each line will contain an evaluation section that
reflects the significance of the assigned human readable description.

h3. 3.1 Pseudo-Code

# Choose 600 best scoring blast results
# Filter description lines of above blast-results using regular expressions:
## Reject those matched by any regex given in e.g. ./test/resources/blacklist_descline.txt,
## Delete those parts of each description line, matching any regex in e.g. ./test/resources/filter_descline_sprot.txt. 
# Divide each description line into tokens (characters of collective meaning)
## In terms of score ignore any tokens matching regexs given e.g. in ./test/resources/blacklist_token.txt.
# Token score (calculated from: bitscore, database weight, overlap score)
# Lexical score (calculated from: Token score, High score factor, Pattern factor, Correction factor)
# Description score (calculated from: Lexical score, GO score, Blast score)
# Choose best scoring description line
# Append InterProScan description to chosen description line if available

h3. 3.2 Used Formulae and Parameters

!https://raw.githubusercontent.com/groupschoof/AHRD/master/images/formulae.jpg!

h3. 3.3 Parameters

Above formulae use the following parameters as given in *./ahrd_example_input.yml*.
These parameters can either be used as provided or can be adapted to your needs.

h4. 3.3.1 The weights in formula Token-Score are

<pre>token_score_bit_score_weight: 0.5
token_score_database_score_weight: 0.3
token_score_overlap_score_weight: 0.2 </pre>
and Blast-Database specific:
<pre>weight: 100 </pre>

h4. 3.3.2 The weight in formula Description-Score also is Blast-database specific

<pre>description_score_bit_score_weight: 0.2 </pre>

h2. 4 Testing

If you want to run the complete JUnit Test-Suite execute: <pre>ant</pre>

h2. 5 License

See attached file LICENSE.txt for details.

h2. 6 Authors

Asis Hallab, Kathrin Klee, Sri Girish, and Prof. Dr. Heiko Schoof

INRES Crop Bioinformatics
University of Bonn
Katzenburgweg 2
53115 Bonn
Germany

h2. References

fn1. Young, Nevin D., Frédéric Debellé, Giles E. D. Oldroyd, Rene Geurts, Steven B. Cannon, Michael K. Udvardi, Vagner A. Benedito, et al. “The Medicago Genome Provides Insight into the Evolution of Rhizobial Symbioses.” Nature 480, no. 7378 (December 22, 2011): 520–24. doi:10.1038/nature10625.
